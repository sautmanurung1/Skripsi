{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# # Load data from CSV file\n",
    "# data = pd.read_csv('Datas_Nilai.csv', sep=';')\n",
    "\n",
    "# # Exclude the first data row\n",
    "# data = data.iloc[1:]\n",
    "\n",
    "# # Replace commas (,) with periods (.) and convert to float\n",
    "# data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# # Extract attributes from the data\n",
    "# attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2']\n",
    "# X = data[attributes].values\n",
    "\n",
    "# # Perform pairwise distance calculation\n",
    "# distances = pairwise_distances(X[:, 1:], metric='euclidean')\n",
    "\n",
    "# # Function to calculate the total dissimilarity for a given medoid index\n",
    "# def total_dissimilarity(index, medoids):\n",
    "#     cluster_indices = np.where(medoids)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "#     return sum(cluster_distances)\n",
    "\n",
    "# # Function to find the best medoid with the lowest dissimilarity\n",
    "# def find_best_medoid(cluster_points, cluster_indices):\n",
    "#     best_medoid = None\n",
    "#     best_dissimilarity = float('inf')\n",
    "#     for i in range(len(cluster_points)):\n",
    "#         dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "#         if np.all(dissimilarity < best_dissimilarity):\n",
    "#             best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "#             best_dissimilarity = dissimilarity\n",
    "#     return best_medoid, best_dissimilarity\n",
    "\n",
    "# # Perform K-Medoids clustering\n",
    "# k = 3  # Number of clusters\n",
    "# medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# # Find the best medoid for each cluster\n",
    "# medoids = []\n",
    "# for cluster_id in range(k):\n",
    "#     cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "#     medoids.append(medoid_index)\n",
    "\n",
    "# # Retrieve all attributes from data\n",
    "# all_attributes = X\n",
    "\n",
    "# # Print all the attributes along with the cluster assignment (starting from 1)\n",
    "# for i, row in enumerate(all_attributes):\n",
    "#     cluster_assignment = medoids_indices[i] + 1\n",
    "#     print(f\"Nama: {row[0]}, Peng Sem 1: {row[1]}, Ket Sem 1: {row[2]}, Peng Sem 2: {row[3]}, Ket Sem 2: {row[4]}, Cluster: {cluster_assignment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# # Load data from CSV file\n",
    "# data = pd.read_csv('Datas_Nilai.csv', sep=';')\n",
    "\n",
    "# # Exclude the first data row\n",
    "# data = data.iloc[1:]\n",
    "\n",
    "# # Remove rows with missing values\n",
    "# data = data.dropna()\n",
    "\n",
    "# # Replace commas (,) with periods (.) and convert to float\n",
    "# data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# # Extract attributes from the data\n",
    "# attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2', 'Kelas Awal']\n",
    "# X = data[attributes].values\n",
    "\n",
    "# # Perform pairwise distance calculation\n",
    "# distances = pairwise_distances(X[:, 1:5], metric='euclidean')\n",
    "\n",
    "# # Function to calculate the total dissimilarity for a given medoid index\n",
    "# def total_dissimilarity(index, medoids):\n",
    "#     cluster_indices = np.where(medoids)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "#     return sum(cluster_distances)\n",
    "\n",
    "# # Function to find the best medoid with the lowest dissimilarity\n",
    "# def find_best_medoid(cluster_points, cluster_indices):\n",
    "#     best_medoid = None\n",
    "#     best_dissimilarity = float('inf')\n",
    "#     for i in range(len(cluster_points)):\n",
    "#         dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "#         if np.all(dissimilarity < best_dissimilarity):\n",
    "#             best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "#             best_dissimilarity = dissimilarity\n",
    "#     return best_medoid, best_dissimilarity\n",
    "\n",
    "# # Perform K-Medoids clustering\n",
    "# k = 3  # Number of clusters\n",
    "# medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# # Find the best medoid for each cluster\n",
    "# medoids = []\n",
    "# for cluster_id in range(k):\n",
    "#     cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "#     medoids.append(medoid_index)\n",
    "\n",
    "# # Retrieve all attributes from data\n",
    "# all_attributes = X\n",
    "\n",
    "# # Create a dictionary to map cluster assignments to new classes\n",
    "# cluster_to_class = {\n",
    "#     0: '7a',\n",
    "#     1: '7b',\n",
    "#     2: '7c',\n",
    "# }\n",
    "\n",
    "# # Append new column 'Kelas Baru' to the DataFrame\n",
    "# data['Kelas Baru'] = ''\n",
    "\n",
    "# # Update the 'Kelas Baru' column with the new class based on the cluster assignment\n",
    "# for i, row in enumerate(all_attributes):\n",
    "#     cluster_assignment = medoids_indices[i]\n",
    "#     new_class = cluster_to_class[cluster_assignment]\n",
    "#     data.loc[i, 'Kelas Baru'] = new_class\n",
    "\n",
    "# # Print the updated DataFrame\n",
    "# print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 count: 51\n",
      "Cluster 2 count: 11\n",
      "Cluster 3 count: 37\n",
      "Cluster 4 count: 33\n",
      "Cluster 5 count: 14\n",
      "Cluster 6 count: 21\n",
      "Cluster 7 count: 47\n",
      "Cluster 8 count: 32\n",
      "        No                           Nama  Peng Sem 1  Ket Sem 1  Peng Sem 2  \\\n",
      "1      2.0  Agustinus Robert Tua Tambunan        76.2       76.7        79.5   \n",
      "2      3.0                  Alisya Kirana        82.6       82.4        85.6   \n",
      "3      4.0       Calista Anggriani Marbun        82.7       82.7        83.7   \n",
      "4      5.0     Chiren Amanda P, Silitonga        79.9       80.2        83.1   \n",
      "5      6.0         Dini Elisabet Dongoran        82.1       81.7        85.4   \n",
      "..     ...                            ...         ...        ...         ...   \n",
      "243  244.0             SEM FELIX PAKPAHAN        77.9       76.9        79.4   \n",
      "244  245.0     Sharah Marcaulina Br,Regar        79.3       78.1        80.0   \n",
      "245  246.0            TIOLENTINA TAMBUNAN        81.7       81.7        83.4   \n",
      "246  247.0      YEBIDA SEPTRIANI PAKPAHAN        81.3       81.3        84.4   \n",
      "0      NaN                            NaN         NaN        NaN         NaN   \n",
      "\n",
      "     Ket Sem 2 Kelas Awal Kelas Baru  \n",
      "1         79.0         7a         7a  \n",
      "2         85.2         7a         7a  \n",
      "3         84.1         7a         7h  \n",
      "4         83.1         7a         7a  \n",
      "5         85.1         7a         7h  \n",
      "..         ...        ...        ...  \n",
      "243       79.8         7h         7c  \n",
      "244       80.1         7h         7a  \n",
      "245       83.1         7h         7a  \n",
      "246       84.3         7h             \n",
      "0          NaN        NaN         7g  \n",
      "\n",
      "[247 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('Data Process.csv', sep=';')\n",
    "\n",
    "# Exclude the first data row\n",
    "data = data.iloc[1:]\n",
    "\n",
    "# Remove rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Replace commas (,) with periods (.) and convert to float\n",
    "data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Extract attributes from the data\n",
    "attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2', 'Kelas Awal']\n",
    "X = data[attributes].values\n",
    "\n",
    "# Perform pairwise distance calculation\n",
    "distances = pairwise_distances(X[:, 1:5], metric='euclidean')\n",
    "\n",
    "# Function to calculate the total dissimilarity for a given medoid index\n",
    "def total_dissimilarity(index, medoids):\n",
    "    cluster_indices = np.where(medoids)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "    return sum(cluster_distances)\n",
    "\n",
    "# Function to find the best medoid with the lowest dissimilarity\n",
    "def find_best_medoid(cluster_points, cluster_indices):\n",
    "    best_medoid = None\n",
    "    best_dissimilarity = float('inf')\n",
    "    for i in range(len(cluster_points)):\n",
    "        dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "        if np.all(dissimilarity < best_dissimilarity):\n",
    "            best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "            best_dissimilarity = dissimilarity\n",
    "    return best_medoid, best_dissimilarity\n",
    "\n",
    "# Perform K-Medoids clustering\n",
    "k = 8 # Number of clusters\n",
    "medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# Find the best medoid for each cluster\n",
    "medoids = []\n",
    "for cluster_id in range(k):\n",
    "    cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "    medoids.append(medoid_index)\n",
    "\n",
    "# Retrieve all attributes from data\n",
    "all_attributes = X\n",
    "\n",
    "# Create a dictionary to map cluster assignments to new classes\n",
    "cluster_to_class = {\n",
    "    0: '7a',\n",
    "    1: '7b',\n",
    "    2: '7c',\n",
    "    3: '7d',\n",
    "    4: '7e',\n",
    "    5: '7f',\n",
    "    6: '7g',\n",
    "    7: '7h'\n",
    "}\n",
    "\n",
    "# Count data points in each cluster\n",
    "cluster_counts = np.bincount(medoids_indices)\n",
    "\n",
    "# Append new column 'Kelas Baru' to the DataFrame\n",
    "data['Kelas Baru'] = ''\n",
    "\n",
    "# Update the 'Kelas Baru' column with the new class based on the cluster assignment\n",
    "for i, row in enumerate(all_attributes):\n",
    "    cluster_assignment = medoids_indices[i]\n",
    "    new_class = cluster_to_class[cluster_assignment]\n",
    "    data.loc[i, 'Kelas Baru'] = new_class\n",
    "\n",
    "data.to_csv('New_Data.csv', index=False)\n",
    "# Print the count of data points in each cluster\n",
    "for cluster_id, count in enumerate(cluster_counts):\n",
    "    print(f\"Cluster {cluster_id + 1} count: {count}\")\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
