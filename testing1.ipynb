{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8436/1494584687.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Perform pairwise distance calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Function to calculate the total dissimilarity for a given medoid index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    270\u001b[0m            [1.41421356]])\n\u001b[0;32m    271\u001b[0m     \"\"\"\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;31m# If norms are passed as float32, they are unused. If arrays are passed as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         X = Y = check_array(X, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0m\u001b[0;32m    143\u001b[0m                             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             estimator=estimator)\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NITRO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('Datas_Nilai.csv', sep=';')\n",
    "\n",
    "# Exclude the first data row\n",
    "data = data.iloc[1:]\n",
    "\n",
    "# Replace commas (,) with periods (.) and convert to float\n",
    "data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Extract attributes from the data\n",
    "attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2']\n",
    "X = data[attributes].values\n",
    "\n",
    "# Perform pairwise distance calculation\n",
    "distances = pairwise_distances(X[:, 1:], metric='euclidean')\n",
    "\n",
    "# Function to calculate the total dissimilarity for a given medoid index\n",
    "def total_dissimilarity(index, medoids):\n",
    "    cluster_indices = np.where(medoids)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "    return sum(cluster_distances)\n",
    "\n",
    "# Function to find the best medoid with the lowest dissimilarity\n",
    "def find_best_medoid(cluster_points, cluster_indices):\n",
    "    best_medoid = None\n",
    "    best_dissimilarity = float('inf')\n",
    "    for i in range(len(cluster_points)):\n",
    "        dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "        if np.all(dissimilarity < best_dissimilarity):\n",
    "            best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "            best_dissimilarity = dissimilarity\n",
    "    return best_medoid, best_dissimilarity\n",
    "\n",
    "# Perform K-Medoids clustering\n",
    "k = 3  # Number of clusters\n",
    "medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# Find the best medoid for each cluster\n",
    "medoids = []\n",
    "for cluster_id in range(k):\n",
    "    cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "    medoids.append(medoid_index)\n",
    "\n",
    "# Retrieve all attributes from data\n",
    "all_attributes = X\n",
    "\n",
    "# Print all the attributes along with the cluster assignment (starting from 1)\n",
    "for i, row in enumerate(all_attributes):\n",
    "    cluster_assignment = medoids_indices[i] + 1\n",
    "    print(f\"Nama: {row[0]}, Peng Sem 1: {row[1]}, Ket Sem 1: {row[2]}, Peng Sem 2: {row[3]}, Ket Sem 2: {row[4]}, Cluster: {cluster_assignment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        No                           Nama  Peng Sem 1  Ket Sem 1  Peng Sem 2  \\\n",
      "1      2.0  Agustinus Robert Tua Tambunan        76.2       76.7        79.5   \n",
      "2      3.0                  Alisya Kirana        82.6       82.4        85.6   \n",
      "3      4.0       Calista Anggriani Marbun        82.7       82.7        83.7   \n",
      "4      5.0     Chiren Amanda P, Silitonga        79.9       80.2        83.1   \n",
      "5      6.0         Dini Elisabet Dongoran        82.1       81.7        85.4   \n",
      "..     ...                            ...         ...        ...         ...   \n",
      "242  243.0             SEM FELIX PAKPAHAN        77.9       76.9        79.4   \n",
      "243  244.0     Sharah Marcaulina Br,Regar        79.3       78.1        80.0   \n",
      "244  245.0            TIOLENTINA TAMBUNAN        81.7       81.7        83.4   \n",
      "245  246.0      YEBIDA SEPTRIANI PAKPAHAN        81.3       81.3        84.4   \n",
      "0      NaN                            NaN         NaN        NaN         NaN   \n",
      "\n",
      "     Ket Sem 2 Kelas Awal Kelas Baru  \n",
      "1         79.0         7a         7a  \n",
      "2         85.2         7a         7a  \n",
      "3         84.1         7a         7c  \n",
      "4         83.1         7a         7a  \n",
      "5         85.1         7a         7c  \n",
      "..         ...        ...        ...  \n",
      "242       79.8         7g         7c  \n",
      "243       80.1         7g         7a  \n",
      "244       83.1         7g         7a  \n",
      "245       84.3         7g             \n",
      "0          NaN        NaN         7b  \n",
      "\n",
      "[246 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('Datas_Nilai.csv', sep=';')\n",
    "\n",
    "# Exclude the first data row\n",
    "data = data.iloc[1:]\n",
    "\n",
    "# Remove rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Replace commas (,) with periods (.) and convert to float\n",
    "data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Extract attributes from the data\n",
    "attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2', 'Kelas Awal']\n",
    "X = data[attributes].values\n",
    "\n",
    "# Perform pairwise distance calculation\n",
    "distances = pairwise_distances(X[:, 1:5], metric='euclidean')\n",
    "\n",
    "# Function to calculate the total dissimilarity for a given medoid index\n",
    "def total_dissimilarity(index, medoids):\n",
    "    cluster_indices = np.where(medoids)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "    return sum(cluster_distances)\n",
    "\n",
    "# Function to find the best medoid with the lowest dissimilarity\n",
    "def find_best_medoid(cluster_points, cluster_indices):\n",
    "    best_medoid = None\n",
    "    best_dissimilarity = float('inf')\n",
    "    for i in range(len(cluster_points)):\n",
    "        dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "        if np.all(dissimilarity < best_dissimilarity):\n",
    "            best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "            best_dissimilarity = dissimilarity\n",
    "    return best_medoid, best_dissimilarity\n",
    "\n",
    "# Perform K-Medoids clustering\n",
    "k = 3  # Number of clusters\n",
    "medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# Find the best medoid for each cluster\n",
    "medoids = []\n",
    "for cluster_id in range(k):\n",
    "    cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "    medoids.append(medoid_index)\n",
    "\n",
    "# Retrieve all attributes from data\n",
    "all_attributes = X\n",
    "\n",
    "# Create a dictionary to map cluster assignments to new classes\n",
    "cluster_to_class = {\n",
    "    0: '7a',\n",
    "    1: '7b',\n",
    "    2: '7c',\n",
    "}\n",
    "\n",
    "# Append new column 'Kelas Baru' to the DataFrame\n",
    "data['Kelas Baru'] = ''\n",
    "\n",
    "# Update the 'Kelas Baru' column with the new class based on the cluster assignment\n",
    "for i, row in enumerate(all_attributes):\n",
    "    cluster_assignment = medoids_indices[i]\n",
    "    new_class = cluster_to_class[cluster_assignment]\n",
    "    data.loc[i, 'Kelas Baru'] = new_class\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        No                           Nama  Peng Sem 1  Ket Sem 1  Peng Sem 2  \\\n",
      "1      2.0  Agustinus Robert Tua Tambunan        76.2       76.7        79.5   \n",
      "2      3.0                  Alisya Kirana        82.6       82.4        85.6   \n",
      "3      4.0       Calista Anggriani Marbun        82.7       82.7        83.7   \n",
      "4      5.0     Chiren Amanda P, Silitonga        79.9       80.2        83.1   \n",
      "5      6.0         Dini Elisabet Dongoran        82.1       81.7        85.4   \n",
      "..     ...                            ...         ...        ...         ...   \n",
      "242  243.0             SEM FELIX PAKPAHAN        77.9       76.9        79.4   \n",
      "243  244.0     Sharah Marcaulina Br,Regar        79.3       78.1        80.0   \n",
      "244  245.0            TIOLENTINA TAMBUNAN        81.7       81.7        83.4   \n",
      "245  246.0      YEBIDA SEPTRIANI PAKPAHAN        81.3       81.3        84.4   \n",
      "0      NaN                            NaN         NaN        NaN         NaN   \n",
      "\n",
      "     Ket Sem 2 Kelas Awal Kelas Baru  \n",
      "1         79.0         7a         7a  \n",
      "2         85.2         7a         7a  \n",
      "3         84.1         7a         7b  \n",
      "4         83.1         7a         7a  \n",
      "5         85.1         7a         7b  \n",
      "..         ...        ...        ...  \n",
      "242       79.8         7g         7e  \n",
      "243       80.1         7g         7a  \n",
      "244       83.1         7g         7a  \n",
      "245       84.3         7g             \n",
      "0          NaN        NaN         7f  \n",
      "\n",
      "[246 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('Datas_Nilai.csv', sep=';')\n",
    "\n",
    "# Exclude the first data row\n",
    "data = data.iloc[1:]\n",
    "\n",
    "# Remove rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Replace commas (,) with periods (.) and convert to float\n",
    "data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Extract attributes from the data\n",
    "attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2', 'Kelas Awal']\n",
    "X = data[attributes].values\n",
    "\n",
    "# Perform pairwise distance calculation\n",
    "distances = pairwise_distances(X[:, 1:5], metric='euclidean')\n",
    "\n",
    "# Function to calculate the total dissimilarity for a given medoid index\n",
    "def total_dissimilarity(index, medoids):\n",
    "    cluster_indices = np.where(medoids)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "    return sum(cluster_distances)\n",
    "\n",
    "# Function to find the best medoid with the lowest dissimilarity\n",
    "def find_best_medoid(cluster_points, cluster_indices):\n",
    "    best_medoid = None\n",
    "    best_dissimilarity = float('inf')\n",
    "    for i in range(len(cluster_points)):\n",
    "        dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "        if np.all(dissimilarity < best_dissimilarity):\n",
    "            best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "            best_dissimilarity = dissimilarity\n",
    "    return best_medoid, best_dissimilarity\n",
    "\n",
    "# Perform K-Medoids clustering\n",
    "k = 7  # Number of clusters\n",
    "medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# Find the best medoid for each cluster\n",
    "medoids = []\n",
    "for cluster_id in range(k):\n",
    "    cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "    medoids.append(medoid_index)\n",
    "\n",
    "# Retrieve all attributes from data\n",
    "all_attributes = X\n",
    "\n",
    "# Create a dictionary to map cluster assignments to new classes\n",
    "cluster_to_class = {\n",
    "    0: '7a',\n",
    "    1: '7b',\n",
    "    2: '7c',\n",
    "    3: '7d',\n",
    "    4: '7e',\n",
    "    5: '7f',\n",
    "    6: '7g'\n",
    "}\n",
    "\n",
    "# Append new column 'Kelas Baru' to the DataFrame\n",
    "data['Kelas Baru'] = ''\n",
    "\n",
    "# Update the 'Kelas Baru' column with the new class based on the cluster assignment\n",
    "for i, row in enumerate(all_attributes):\n",
    "    cluster_assignment = medoids_indices[i]\n",
    "    new_class = cluster_to_class[cluster_assignment]\n",
    "    data.loc[i, 'Kelas Baru'] = new_class\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "data.to_csv('New_Data_new.csv', index=False)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
