{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# # Load data from CSV file\n",
    "# data = pd.read_csv('Data Process.csv', sep=';')\n",
    "\n",
    "# # Exclude the first data row\n",
    "# data = data.iloc[1:]\n",
    "\n",
    "# # Replace commas (,) with periods (.) and convert to float\n",
    "# data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# # Extract attributes from the data\n",
    "# attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2']\n",
    "# X = data[attributes].values\n",
    "\n",
    "# # Perform pairwise distance calculation\n",
    "# distances = pairwise_distances(X[:, 1:], metric='euclidean')\n",
    "\n",
    "# # Function to calculate the total dissimilarity for a given medoid index\n",
    "# def total_dissimilarity(index, medoids):\n",
    "#     cluster_indices = np.where(medoids)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "#     return sum(cluster_distances)\n",
    "\n",
    "# # Function to find the best medoid with the lowest dissimilarity\n",
    "# def find_best_medoid(cluster_points, cluster_indices):\n",
    "#     best_medoid = None\n",
    "#     best_dissimilarity = float('inf')\n",
    "#     for i in range(len(cluster_points)):\n",
    "#         dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "#         if np.all(dissimilarity < best_dissimilarity):\n",
    "#             best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "#             best_dissimilarity = dissimilarity\n",
    "#     return best_medoid, best_dissimilarity\n",
    "\n",
    "# # Perform K-Medoids clustering\n",
    "# k = 3  # Number of clusters\n",
    "# medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# # Find the best medoid for each cluster\n",
    "# medoids = []\n",
    "# for cluster_id in range(k):\n",
    "#     cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "#     medoids.append(medoid_index)\n",
    "\n",
    "# # Retrieve all attributes from data\n",
    "# all_attributes = X\n",
    "\n",
    "# # Print all the attributes along with the cluster assignment (starting from 1)\n",
    "# for i, row in enumerate(all_attributes):\n",
    "#     cluster_assignment = medoids_indices[i] + 1\n",
    "#     print(f\"Nama: {row[0]}, Peng Sem 1: {row[1]}, Ket Sem 1: {row[2]}, Peng Sem 2: {row[3]}, Ket Sem 2: {row[4]}, Cluster: {cluster_assignment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    95\n",
      "1    85\n",
      "3    66\n",
      "Name: Cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('Data Process.csv', sep=';')\n",
    "\n",
    "# Exclude the first data row\n",
    "data = data.iloc[1:]\n",
    "\n",
    "# Replace commas (,) with periods (.) and convert to float\n",
    "data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Extract attributes from the data\n",
    "attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2']\n",
    "X = data[attributes].values\n",
    "\n",
    "# Perform pairwise distance calculation\n",
    "distances = pairwise_distances(X[:, 1:], metric='euclidean')\n",
    "\n",
    "# Function to calculate the total dissimilarity for a given medoid index\n",
    "def total_dissimilarity(index, medoids):\n",
    "    cluster_indices = np.where(medoids)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "    return sum(cluster_distances)\n",
    "\n",
    "# Function to find the best medoid with the lowest dissimilarity\n",
    "def find_best_medoid(cluster_points, cluster_indices):\n",
    "    best_medoid = None\n",
    "    best_dissimilarity = float('inf')\n",
    "    for i in range(len(cluster_points)):\n",
    "        dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "        if np.all(dissimilarity < best_dissimilarity):\n",
    "            best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "            best_dissimilarity = dissimilarity\n",
    "    return best_medoid, best_dissimilarity\n",
    "\n",
    "# Perform K-Medoids clustering\n",
    "k = 3  # Number of clusters\n",
    "medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# Find the best medoid for each cluster\n",
    "medoids = []\n",
    "for cluster_id in range(k):\n",
    "    cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "    cluster_points = X[cluster_indices]\n",
    "    medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "    medoids.append(medoid_index)\n",
    "\n",
    "# Retrieve all attributes from data\n",
    "all_attributes = X\n",
    "\n",
    "# Create a new DataFrame with cluster assignments\n",
    "cluster_data = pd.DataFrame(all_attributes, columns=attributes)\n",
    "cluster_data['Cluster'] = medoids_indices + 1\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "cluster_data.to_csv('Clustered_Data.csv', index=False)\n",
    "cluster_counts = cluster_data['Cluster'].value_counts()\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# # Load data from CSV file\n",
    "# data = pd.read_csv('Datas_Nilai.csv', sep=';')\n",
    "\n",
    "# # Exclude the first data row\n",
    "# data = data.iloc[1:]\n",
    "\n",
    "# # Remove rows with missing values\n",
    "# data = data.dropna()\n",
    "\n",
    "# # Replace commas (,) with periods (.) and convert to float\n",
    "# data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# # Extract attributes from the data\n",
    "# attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2', 'Kelas Awal']\n",
    "# X = data[attributes].values\n",
    "\n",
    "# # Perform pairwise distance calculation\n",
    "# distances = pairwise_distances(X[:, 1:5], metric='euclidean')\n",
    "\n",
    "# # Function to calculate the total dissimilarity for a given medoid index\n",
    "# def total_dissimilarity(index, medoids):\n",
    "#     cluster_indices = np.where(medoids)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "#     return sum(cluster_distances)\n",
    "\n",
    "# # Function to find the best medoid with the lowest dissimilarity\n",
    "# def find_best_medoid(cluster_points, cluster_indices):\n",
    "#     best_medoid = None\n",
    "#     best_dissimilarity = float('inf')\n",
    "#     for i in range(len(cluster_points)):\n",
    "#         dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "#         if np.all(dissimilarity < best_dissimilarity):\n",
    "#             best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "#             best_dissimilarity = dissimilarity\n",
    "#     return best_medoid, best_dissimilarity\n",
    "\n",
    "# # Perform K-Medoids clustering\n",
    "# k = 3  # Number of clusters\n",
    "# medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# # Find the best medoid for each cluster\n",
    "# medoids = []\n",
    "# for cluster_id in range(k):\n",
    "#     cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "#     medoids.append(medoid_index)\n",
    "\n",
    "# # Retrieve all attributes from data\n",
    "# all_attributes = X\n",
    "\n",
    "# # Create a dictionary to map cluster assignments to new classes\n",
    "# cluster_to_class = {\n",
    "#     0: '7a',\n",
    "#     1: '7b',\n",
    "#     2: '7c',\n",
    "# }\n",
    "\n",
    "# # Append new column 'Kelas Baru' to the DataFrame\n",
    "# data['Kelas Baru'] = ''\n",
    "\n",
    "# # Update the 'Kelas Baru' column with the new class based on the cluster assignment\n",
    "# for i, row in enumerate(all_attributes):\n",
    "#     cluster_assignment = medoids_indices[i]\n",
    "#     new_class = cluster_to_class[cluster_assignment]\n",
    "#     data.loc[i, 'Kelas Baru'] = new_class\n",
    "\n",
    "# # Print the updated DataFrame\n",
    "# print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# # Load data from CSV file\n",
    "# data = pd.read_csv('Data Process.csv', sep=';')\n",
    "\n",
    "# # Exclude the first data row\n",
    "# data = data.iloc[1:]\n",
    "\n",
    "# # Remove rows with missing values\n",
    "# data = data.dropna()\n",
    "\n",
    "# # Replace commas (,) with periods (.) and convert to float\n",
    "# data['Peng Sem 1'] = data['Peng Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Peng Sem 2'] = data['Peng Sem 2'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 1'] = data['Ket Sem 1'].str.replace(',', '.').astype(float)\n",
    "# data['Ket Sem 2'] = data['Ket Sem 2'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# # Extract attributes from the data\n",
    "# attributes = ['Nama', 'Peng Sem 1', 'Ket Sem 1', 'Peng Sem 2', 'Ket Sem 2', 'Kelas Awal']\n",
    "# X = data[attributes].values\n",
    "\n",
    "# # Perform pairwise distance calculation\n",
    "# distances = pairwise_distances(X[:, 1:5], metric='euclidean')\n",
    "\n",
    "# # Function to calculate the total dissimilarity for a given medoid index\n",
    "# def total_dissimilarity(index, medoids):\n",
    "#     cluster_indices = np.where(medoids)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     cluster_distances = distances[cluster_indices][:, cluster_indices]\n",
    "#     return sum(cluster_distances)\n",
    "\n",
    "# # Function to find the best medoid with the lowest dissimilarity\n",
    "# def find_best_medoid(cluster_points, cluster_indices):\n",
    "#     best_medoid = None\n",
    "#     best_dissimilarity = float('inf')\n",
    "#     for i in range(len(cluster_points)):\n",
    "#         dissimilarity = total_dissimilarity(i, cluster_indices)\n",
    "#         if np.all(dissimilarity < best_dissimilarity):\n",
    "#             best_medoid = cluster_indices[i]  # Update with cluster index\n",
    "#             best_dissimilarity = dissimilarity\n",
    "#     return best_medoid, best_dissimilarity\n",
    "\n",
    "# # Perform K-Medoids clustering\n",
    "# k = 8 # Number of clusters\n",
    "# medoids_indices = KMedoids(n_clusters=k, random_state=0).fit_predict(distances)\n",
    "\n",
    "# # Find the best medoid for each cluster\n",
    "# medoids = []\n",
    "# for cluster_id in range(k):\n",
    "#     cluster_indices = np.where(medoids_indices == cluster_id)[0]\n",
    "#     cluster_points = X[cluster_indices]\n",
    "#     medoid_index, _ = find_best_medoid(cluster_points, cluster_indices)\n",
    "#     medoids.append(medoid_index)\n",
    "\n",
    "# # Retrieve all attributes from data\n",
    "# all_attributes = X\n",
    "\n",
    "# # Create a dictionary to map cluster assignments to new classes\n",
    "# cluster_to_class = {\n",
    "#     0: '7a',\n",
    "#     1: '7b',\n",
    "#     2: '7c',\n",
    "#     3: '7d',\n",
    "#     4: '7e',\n",
    "#     5: '7f',\n",
    "#     6: '7g',\n",
    "#     7: '7h'\n",
    "# }\n",
    "\n",
    "# # Count data points in each cluster\n",
    "# cluster_counts = np.bincount(medoids_indices)\n",
    "\n",
    "# # Append new column 'Kelas Baru' to the DataFrame\n",
    "# data['Kelas Baru'] = ''\n",
    "\n",
    "# # Update the 'Kelas Baru' column with the new class based on the cluster assignment\n",
    "# for i, row in enumerate(all_attributes):\n",
    "#     cluster_assignment = medoids_indices[i]\n",
    "#     new_class = cluster_to_class[cluster_assignment]\n",
    "#     data.loc[i, 'Kelas Baru'] = new_class\n",
    "\n",
    "# # Print the count of data points in each cluster\n",
    "# for cluster_id, count in enumerate(cluster_counts):\n",
    "#     print(f\"Cluster {cluster_id + 1} count: {count}\")\n",
    "\n",
    "# # Print the updated DataFrame\n",
    "# print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
